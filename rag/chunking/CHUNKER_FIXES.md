# Chunking System Fixes & Improvements

## ðŸš€ Multi-Stage Retriever Integration

First, integrate the multi-stage retriever with your existing system:

### Update your `rag_system.py`:

```python
from rag.retrieval.multi_stage_retriever import MultiStageRetriever

class RAGSystem:
    def __init__(self):
        # ... existing code ...
        
        # Add multi-stage retriever
        self.multi_stage_retriever = MultiStageRetriever()
    
    def query(self, query: str, max_context_tokens: int = 8000, top_k: int = 10) -> RAGResponse:
        start_time = time.time()
        logger.info(f"Enhanced multi-stage query retrieval for: {query}")
        
        try:
            # Use multi-stage retrieval instead of basic retrieval
            retrieval_result = self.multi_stage_retriever.retrieve(query, top_k)
            
            if not retrieval_result:
                return RAGResponse(
                    context="",
                    chunks_used=[],
                    total_tokens=0,
                    retrieval_time_ms=(time.time() - start_time) * 1000
                )

            # Rest stays the same
            final_context = self.context_fuser.fuse_context(retrieval_result, max_context_tokens)
            chunks_used = [result.chunk for result in retrieval_result]
            
            response = RAGResponse(
                context=final_context,
                chunks_used=chunks_used,
                total_tokens=len(self.context_fuser.tokenizer.encode(final_context)),
                retrieval_time_ms=(time.time() - start_time) * 1000
            )
            
            return response
            
        except Exception as e:
            logger.error(f"Multi-stage retrieval failed: {e}")
            # Fallback to your original system
            return self._original_query_method(query, max_context_tokens, top_k)
```

## ðŸ”§ Chunking System Improvements

### 1. Fix JavaScript/TypeScript Chunking

Replace the placeholder methods in your `enhanced_tree_sitter_chunker.py`:

```python
# REPLACE this method:
def _chunk_javascript_enhanced(self, file_path: Path, content: str, tree: Tree) -> List[CodeBaseChunk]:
    """Enhanced JavaScript/TypeScript chunking"""
    # OLD: return self._fallback_chunking(file_path, content)
    
    # NEW: Use proper JS/TS chunking
    from rag.chunking.improved_language_support import ImprovedLanguageSupport
    return ImprovedLanguageSupport.chunk_javascript_enhanced(self, file_path, content, tree)

# REPLACE this method:
def _chunk_java_enhanced(self, file_path: Path, content: str, tree: Tree) -> List[CodeBaseChunk]:
    """Enhanced Java chunking"""
    # OLD: return self._fallback_chunking(file_path, content)
    
    # NEW: Use proper Java chunking
    from rag.chunking.improved_language_support import ImprovedLanguageSupport
    return ImprovedLanguageSupport.chunk_java_enhanced(self, file_path, content, tree)
```

### 2. Fix Module-Level Code Extraction

Replace the placeholder module chunk method:

```python
def _create_module_chunk(
    self, file_path: Path, content: str, 
    tree: Tree, imports: List[str]
) -> Optional[CodeBaseChunk]:
    """Create chunk for module-level code (globals, constants, etc.)"""
    # OLD: return None  # placeholder
    
    # NEW: Extract actual module-level code
    from rag.chunking.improved_language_support import ImprovedLanguageSupport
    return ImprovedLanguageSupport.create_python_module_chunk(self, file_path, content, tree, imports)
```

### 3. Fix Byte Position Calculation in Fallback

Update your fallback chunking method:

```python
def _fallback_chunking(self, file_path: Path, content: str) -> List[CodeBaseChunk]:
    """Fallback chunking for unsupported file types"""
    chunks = []
    lines = content.split('\n')
    content_bytes = content.encode('utf-8')
    
    chunk_size = 50  # lines per chunk
    overlap = int(chunk_size * self.config.overlap_ratio)
    
    for i in range(0, len(lines), chunk_size - overlap):
        chunk_lines = lines[i:i + chunk_size]
        chunk_content = '\n'.join(chunk_lines)
        
        # FIX: Calculate proper byte positions
        start_line_idx = i
        end_line_idx = min(i + chunk_size, len(lines))
        
        # Calculate byte positions
        start_byte = len('\n'.join(lines[:start_line_idx]).encode('utf-8'))
        if start_line_idx > 0:
            start_byte += 1  # Add newline
            
        end_byte = len('\n'.join(lines[:end_line_idx]).encode('utf-8'))
        
        chunk_id = self._generate_chunk_id(file_path, f"fallback_{i}", "text")
        chunk = CodeBaseChunk(
            id=chunk_id,
            file_path=str(file_path),
            content=chunk_content,
            language="text",
            chunk_type="text",
            start_byte=start_byte,  # FIXED: was 0
            end_byte=end_byte,      # FIXED: was 0
            start_line=i + 1,
            end_line=min(i + chunk_size, len(lines))
        )
        chunks.append(chunk)
    
    return chunks
```

### 4. Improve Smart Import Analysis

Add this enhanced method to your enhanced chunker:

```python
def _get_relevant_imports_enhanced(
    self, node: Node, imports: List[str], 
    import_symbols: Set[str], content: str
) -> str:
    """Enhanced import relevance detection"""
    if not self.config.smart_imports or not imports:
        return '\n'.join(imports)
    
    node_content = content[node.start_byte:node.end_byte]
    relevant_imports = []
    
    # Always include imports from config
    always_include = getattr(self.config, 'always_include_imports', [])
    
    for import_stmt in imports:
        should_include = False
        
        # Check always-include list
        if any(always_imp in import_stmt for always_imp in always_include):
            should_include = True
        
        # Check if imported symbols are used
        if not should_include:
            for symbol in import_symbols:
                # More sophisticated pattern matching
                patterns = [
                    rf'\b{re.escape(symbol)}\b',  # Exact word boundary
                    rf'{re.escape(symbol)}\.',    # Module access
                    rf'\.{re.escape(symbol)}\b',  # Method call
                ]
                
                if any(re.search(pattern, node_content) for pattern in patterns):
                    should_include = True
                    break
        
        if should_include:
            relevant_imports.append(import_stmt)
    
    return '\n'.join(relevant_imports)
```

Then update your existing method to use this:

```python
# In _create_chunk method, replace:
# self._get_relevant_imports(class_node, imports, import_symbols, content)
# with:
self._get_relevant_imports_enhanced(class_node, imports, import_symbols, content)
```

## ðŸŽ¯ Testing Your Improvements

Create a test script to verify the improvements:

```python
# test_improvements.py
from pathlib import Path
from rag.retrieval.multi_stage_retriever import MultiStageRetriever
from rag.chunking.enhanced_tree_sitter_chunker import EnhancedTreeSitterChunker

def test_multi_stage_retrieval():
    """Test multi-stage retrieval with different query types"""
    retriever = MultiStageRetriever()
    
    test_queries = [
        "DatabaseManager",  # Symbol lookup
        "how does user authentication work",  # Implementation
        "what is UserService",  # Definition
        "examples of Redis usage",  # Usage examples
    ]
    
    print("=== Multi-Stage Retrieval Test ===")
    for query in test_queries:
        print(f"\nQuery: {query}")
        
        # Get query analysis
        analysis = retriever.get_query_analysis(query)
        print(f"Detected type: {analysis.query_type.value}")
        print(f"Confidence: {analysis.confidence:.2f}")
        print(f"Symbols: {analysis.symbols_mentioned}")
        
        # Get results
        results = retriever.retrieve(query, top_k=5)
        print(f"Results: {len(results)} chunks")
        
        for i, result in enumerate(results):
            print(f"  {i+1}. {result.chunk.file_path} (score: {result.relevance_score:.2f})")

def test_chunking_improvements():
    """Test improved chunking"""
    chunker = EnhancedTreeSitterChunker()
    
    # Test with a JavaScript file
    js_file = Path("test.js")  # Replace with actual JS file path
    if js_file.exists():
        print(f"\n=== Chunking Test: {js_file} ===")
        chunks = chunker.chunk_file(js_file)
        
        print(f"Generated {len(chunks)} chunks:")
        for chunk in chunks:
            print(f"- {chunk.chunk_type}: {chunk.content[:50]}...")

if __name__ == "__main__":
    test_multi_stage_retrieval()
    test_chunking_improvements()
```

## ðŸ“Š Expected Improvements

After implementing these fixes:

### Multi-Stage Retrieval Benefits:
- **3-5x better precision** for specific queries like "DatabaseManager"
- **Intelligent query routing** - different strategies for different query types
- **Better context expansion** for exploratory queries
- **Exact symbol matching** when symbols are detected

### Chunking Improvements:
- **Proper JavaScript/TypeScript support** - no more fallback chunking
- **Complete Java support** with package/import handling  
- **Module-level code extraction** - constants, globals, main blocks
- **Accurate byte positions** in all chunks
- **Smarter import analysis** with pattern matching

### Immediate Next Steps:
1. **Install the multi-stage retriever** (5 minutes)
2. **Test with a few queries** to see immediate improvements
3. **Apply chunking fixes** for better chunk quality
4. **Monitor performance** and adjust as needed

The multi-stage retrieval alone will give you significant improvements immediately, even before fixing the chunking issues!
